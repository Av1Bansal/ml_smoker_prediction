{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046821ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5580885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\kaggle datasets\\playground-series-s3e24\\train.csv\")\n",
    "x_test = pd.read_csv(r\"D:\\kaggle datasets\\playground-series-s3e24\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c8b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BMI\"] = df[\"weight(kg)\"] / ((df[\"height(cm)\"] / 100) ** 2)\n",
    "df[\"waist_height_ratio\"] = df[\"waist(cm)\"] / df[\"height(cm)\"]\n",
    "df[\"cholesterol_hdl_ratio\"] = df[\"Cholesterol\"] / df[\"HDL\"]\n",
    "df[\"ldl_hdl_ratio\"] = df[\"LDL\"] / df[\"HDL\"]\n",
    "df[\"triglyceride_hdl_ratio\"] = df[\"triglyceride\"] / df[\"HDL\"]\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"smoking\"])\n",
    "y = df[\"smoking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cf4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612aea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True)\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8940d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:29:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:29:33,510] Trial 13 finished with value: 0.780641717945498 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'learning_rate': 0.02174841055861922, 'subsample': 0.5168068022803978, 'colsample_bytree': 0.6908573976077236, 'gamma': 0.18712320021873552, 'reg_alpha': 2.908801506010217e-06, 'reg_lambda': 5.630348494561821}. Best is trial 11 with value: 0.7807045083511239.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:29:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:29:47,400] Trial 14 finished with value: 0.7826196157227175 and parameters: {'n_estimators': 813, 'max_depth': 8, 'learning_rate': 0.025305793337317705, 'subsample': 0.506184905340631, 'colsample_bytree': 0.7262529425308694, 'gamma': 0.03496716930861399, 'reg_alpha': 9.334512747637693e-06, 'reg_lambda': 5.887406174231734}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:29:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:30:00,642] Trial 15 finished with value: 0.7818347356523924 and parameters: {'n_estimators': 772, 'max_depth': 8, 'learning_rate': 0.03443389236626285, 'subsample': 0.602845379935396, 'colsample_bytree': 0.9974024384531143, 'gamma': 0.8996405252624495, 'reg_alpha': 6.803703212010341e-05, 'reg_lambda': 0.030792530029681513}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:30:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:30:18,834] Trial 16 finished with value: 0.7820858972748964 and parameters: {'n_estimators': 769, 'max_depth': 8, 'learning_rate': 0.03406363176053929, 'subsample': 0.6031574247646807, 'colsample_bytree': 0.8057080031177075, 'gamma': 0.9320695810195081, 'reg_alpha': 8.855155011889976e-05, 'reg_lambda': 0.0845806213046742}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:30:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:30:29,504] Trial 17 finished with value: 0.7802963707145548 and parameters: {'n_estimators': 731, 'max_depth': 5, 'learning_rate': 0.03417284616482086, 'subsample': 0.5081898756760859, 'colsample_bytree': 0.7781682169602439, 'gamma': 0.91805536774737, 'reg_alpha': 7.494250826489959, 'reg_lambda': 5.963417225261122}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:30:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:30:48,199] Trial 18 finished with value: 0.781018460379254 and parameters: {'n_estimators': 834, 'max_depth': 8, 'learning_rate': 0.01682559081434396, 'subsample': 0.6108431758779256, 'colsample_bytree': 0.8220967919253248, 'gamma': 0.8794571541469534, 'reg_alpha': 3.292559942442692e-05, 'reg_lambda': 0.21445135847942107}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:30:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:30:57,438] Trial 19 finished with value: 0.7801079994976767 and parameters: {'n_estimators': 650, 'max_depth': 6, 'learning_rate': 0.09786531970861559, 'subsample': 0.5578542959802099, 'colsample_bytree': 0.8864898684592284, 'gamma': 0.04213573186364738, 'reg_alpha': 0.0008966167322629929, 'reg_lambda': 0.4933507480104614}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:30:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:31:07,677] Trial 20 finished with value: 0.7800138138892377 and parameters: {'n_estimators': 504, 'max_depth': 8, 'learning_rate': 0.03230986982690564, 'subsample': 0.6430605057083347, 'colsample_bytree': 0.7405140457691112, 'gamma': 0.6997651903540083, 'reg_alpha': 0.04758371863537392, 'reg_lambda': 0.01328230568799096}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:31:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:31:22,204] Trial 21 finished with value: 0.7813324124073842 and parameters: {'n_estimators': 747, 'max_depth': 8, 'learning_rate': 0.041662624980785636, 'subsample': 0.5622913479324456, 'colsample_bytree': 0.9489943447387394, 'gamma': 1.155135379355207, 'reg_alpha': 4.847673669141472e-05, 'reg_lambda': 0.023664516377260098}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:31:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:31:39,587] Trial 22 finished with value: 0.7810812507848801 and parameters: {'n_estimators': 813, 'max_depth': 8, 'learning_rate': 0.02749788178288673, 'subsample': 0.6243037568111846, 'colsample_bytree': 0.9907987425191558, 'gamma': 0.5936636684869705, 'reg_alpha': 0.00018739188097548182, 'reg_lambda': 0.02335640215119517}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:31:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:31:54,164] Trial 23 finished with value: 0.7786638201682783 and parameters: {'n_estimators': 707, 'max_depth': 9, 'learning_rate': 0.04280077092829784, 'subsample': 0.5019701706430746, 'colsample_bytree': 0.6936758294014937, 'gamma': 2.6588388913083176, 'reg_alpha': 7.695269918274985e-06, 'reg_lambda': 0.9110523418532949}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:31:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:32:10,392] Trial 24 finished with value: 0.7821486876805224 and parameters: {'n_estimators': 823, 'max_depth': 7, 'learning_rate': 0.019596430379470203, 'subsample': 0.5886533812993818, 'colsample_bytree': 0.824371749766601, 'gamma': 1.1810413557675883, 'reg_alpha': 2.5764680013964203e-07, 'reg_lambda': 0.0028157454513499424}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:32:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:32:24,700] Trial 25 finished with value: 0.7806103227426849 and parameters: {'n_estimators': 885, 'max_depth': 6, 'learning_rate': 0.017704178582085908, 'subsample': 0.5445477389679968, 'colsample_bytree': 0.8381174735536397, 'gamma': 0.03128433631521932, 'reg_alpha': 1.1705224400225566e-07, 'reg_lambda': 0.0036989590752232867}. Best is trial 14 with value: 0.7826196157227175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:32:33,510] Trial 26 finished with value: 0.7803591611201809 and parameters: {'n_estimators': 830, 'max_depth': 5, 'learning_rate': 0.024646654963985718, 'subsample': 0.6414443505867148, 'colsample_bytree': 0.7898579336791169, 'gamma': 1.7600908631682974, 'reg_alpha': 4.3961687982297903e-07, 'reg_lambda': 0.0002197013094604724}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:32:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:32:42,707] Trial 27 finished with value: 0.7801079994976767 and parameters: {'n_estimators': 676, 'max_depth': 7, 'learning_rate': 0.015107659377525885, 'subsample': 0.7541185462936127, 'colsample_bytree': 0.8779725683888379, 'gamma': 1.1400240153914807, 'reg_alpha': 8.04535256236618e-06, 'reg_lambda': 1.4602151095094718}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:32:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:32:51,725] Trial 28 finished with value: 0.7801707899033028 and parameters: {'n_estimators': 918, 'max_depth': 5, 'learning_rate': 0.02010820384014703, 'subsample': 0.589440388014131, 'colsample_bytree': 0.7629557896474962, 'gamma': 2.237862305544366, 'reg_alpha': 1.7636136783614398e-07, 'reg_lambda': 0.12574842973683587}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:32:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:33:01,171] Trial 29 finished with value: 0.7796998618611076 and parameters: {'n_estimators': 802, 'max_depth': 7, 'learning_rate': 0.05577814252229487, 'subsample': 0.536613618658153, 'colsample_bytree': 0.813180436079663, 'gamma': 1.3286989176478472, 'reg_alpha': 7.736224410330501e-06, 'reg_lambda': 0.0014009175550697866}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:33:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:33:07,890] Trial 30 finished with value: 0.7788835865879694 and parameters: {'n_estimators': 618, 'max_depth': 6, 'learning_rate': 0.013432100099441558, 'subsample': 0.657605833616321, 'colsample_bytree': 0.7020627393814647, 'gamma': 0.48414006758846706, 'reg_alpha': 0.0006826328416286879, 'reg_lambda': 2.3084737687121075}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:33:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:33:19,952] Trial 31 finished with value: 0.7810498555820671 and parameters: {'n_estimators': 796, 'max_depth': 8, 'learning_rate': 0.03721202179529825, 'subsample': 0.5930286829367073, 'colsample_bytree': 0.9737110150420047, 'gamma': 0.9695291564794845, 'reg_alpha': 7.696769643576608e-05, 'reg_lambda': 0.07762627956613875}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:33:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:33:33,351] Trial 32 finished with value: 0.7817719452467663 and parameters: {'n_estimators': 856, 'max_depth': 8, 'learning_rate': 0.029574133907718972, 'subsample': 0.6791424185390575, 'colsample_bytree': 0.9189264945412559, 'gamma': 0.7109462317525947, 'reg_alpha': 0.00617451878941049, 'reg_lambda': 0.010263680016629875}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:33:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:33:48,898] Trial 33 finished with value: 0.7792289338189125 and parameters: {'n_estimators': 941, 'max_depth': 9, 'learning_rate': 0.04705910236152584, 'subsample': 0.6000775313966692, 'colsample_bytree': 0.80164983009695, 'gamma': 1.5842790898169674, 'reg_alpha': 1.6288219432452112e-05, 'reg_lambda': 0.0032071643888241827}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:33:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:33:57,973] Trial 34 finished with value: 0.7787266105739044 and parameters: {'n_estimators': 767, 'max_depth': 7, 'learning_rate': 0.06943873388816947, 'subsample': 0.5356283161954066, 'colsample_bytree': 0.8599487907937768, 'gamma': 1.783324712858915, 'reg_alpha': 0.00020276338593912873, 'reg_lambda': 0.04583031374185831}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:33:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:34:06,599] Trial 35 finished with value: 0.7812068315961321 and parameters: {'n_estimators': 700, 'max_depth': 7, 'learning_rate': 0.02224599996789145, 'subsample': 0.7474254289971987, 'colsample_bytree': 0.7201964727338472, 'gamma': 0.34028161734561113, 'reg_alpha': 0.001867206402532881, 'reg_lambda': 0.00010383683377873544}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:34:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:34:14,317] Trial 36 finished with value: 0.7620557578801959 and parameters: {'n_estimators': 587, 'max_depth': 8, 'learning_rate': 0.2712561493885793, 'subsample': 0.5700449444723737, 'colsample_bytree': 0.6620752513164481, 'gamma': 1.2272330703705732, 'reg_alpha': 3.6170927366304234e-07, 'reg_lambda': 0.3112554635912012}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:34:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:34:21,306] Trial 37 finished with value: 0.7800766042948637 and parameters: {'n_estimators': 364, 'max_depth': 9, 'learning_rate': 0.03427982562212868, 'subsample': 0.619903342482352, 'colsample_bytree': 0.7596919340669628, 'gamma': 1.5039618037192228, 'reg_alpha': 1.9962146022010314e-08, 'reg_lambda': 9.389560703715688}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:34:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:34:29,072] Trial 38 finished with value: 0.7683975888484239 and parameters: {'n_estimators': 770, 'max_depth': 8, 'learning_rate': 0.2071490168599273, 'subsample': 0.6638714392815228, 'colsample_bytree': 0.9068519256511022, 'gamma': 2.0533764723087016, 'reg_alpha': 2.6861540064914045e-06, 'reg_lambda': 0.005440797058937269}. Best is trial 14 with value: 0.7826196157227175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:34:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:34:40,083] Trial 39 finished with value: 0.7796998618611076 and parameters: {'n_estimators': 861, 'max_depth': 7, 'learning_rate': 0.09300816820335069, 'subsample': 0.7057804395907151, 'colsample_bytree': 0.8499489621456732, 'gamma': 0.8021546657199212, 'reg_alpha': 0.04805940169053744, 'reg_lambda': 0.0006632726875053539}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:34:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:34:52,965] Trial 40 finished with value: 0.780955669973628 and parameters: {'n_estimators': 911, 'max_depth': 7, 'learning_rate': 0.012882801840016792, 'subsample': 0.8163374605391676, 'colsample_bytree': 0.9422041257344227, 'gamma': 3.175379639252462, 'reg_alpha': 0.0005045640647385102, 'reg_lambda': 2.2167842235169804e-06}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:34:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-01 18:35:06,279] Trial 41 finished with value: 0.7810812507848801 and parameters: {'n_estimators': 841, 'max_depth': 8, 'learning_rate': 0.02803894920165379, 'subsample': 0.6845009709905266, 'colsample_bytree': 0.9676312149495838, 'gamma': 0.6090603541275821, 'reg_alpha': 0.00843931747323159, 'reg_lambda': 0.009612908136118425}. Best is trial 14 with value: 0.7826196157227175.\n",
      "D:\\conda venv\\python_3.10\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:35:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da56d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "final_model = XGBClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "feature_names = X.columns\n",
    "importances = final_model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18222127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "x_test[\"BMI\"] = x_test[\"weight(kg)\"] / ((x_test[\"height(cm)\"] / 100) ** 2)\n",
    "x_test[\"waist_height_ratio\"] = x_test[\"waist(cm)\"] / x_test[\"height(cm)\"]\n",
    "x_test[\"cholesterol_hdl_ratio\"] = x_test[\"Cholesterol\"] / x_test[\"HDL\"]\n",
    "x_test[\"ldl_hdl_ratio\"] = x_test[\"LDL\"] / x_test[\"HDL\"]\n",
    "x_test[\"triglyceride_hdl_ratio\"] = x_test[\"triglyceride\"] / x_test[\"HDL\"]\n",
    "x_test = x_test.drop(columns=[\"id\"])\n",
    "\n",
    "joblib.dump(final_model, \"model2.pkl\")\n",
    "loaded_model = joblib.load(\"model2.pkl\")\n",
    "pred = loaded_model.predict(x_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38dfadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submission_df = pd.DataFrame({\n",
    "# #     'id':x_test['id'],\n",
    "# #     'smoking': pred\n",
    "# })\n",
    "# # file_path = r\"D:\\kaggle datasets\\playground s5ep10\\playground-series-s5e10\\my_submission5.csv\"\n",
    "# # submission_df.to_csv(file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543d891-21fd-4944-8a99-499c5e9d993c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.10) pytorch",
   "language": "python",
   "name": "python_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
